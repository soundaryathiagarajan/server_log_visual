{
  "name": "kafkaesque",
  "description": "A node client for kafka, supporting upwards of v0.8 of the Kafka protocol, including commit/offset/fetch API. Does not require zookeeper integration",
  "keywords": [
    "apache",
    "kafka",
    "client",
    "0.8",
    "0.9"
  ],
  "version": "0.1.1",
  "license": "MIT",
  "author": {
    "name": "Peter Elger",
    "url": "http://www.nearform.com/"
  },
  "contributors": [
    {
      "name": "Peter Elger",
      "email": "elger.peter@gmail.com",
      "url": "http://peterelger.com/"
    },
    {
      "name": "Richard Rodger",
      "email": "richard@ricebridge.com",
      "url": "http://richardrodger.com/"
    }
  ],
  "engines": {
    "node": "*"
  },
  "dependencies": {
    "underscore": "~1.4.2",
    "buffer-builder": "~0.1.0",
    "buffer-crc32": "~0.2.1",
    "uuid": "~1.4.1",
    "hexy": "~0.2.5"
  },
  "main": "lib/kafkaesque",
  "repository": {
    "type": "git",
    "url": "https://github.com/pelger/Kafkaesque.git"
  },
  "devDependencies": {
    "grunt": "~0.4.1",
    "grunt-contrib-jshint": "~0.6.0",
    "load-grunt-tasks": "~0.1.0",
    "chai": "~1.8.1",
    "matchdep": "~0.3.0",
    "mocha": "~1.13.0",
    "grunt-mocha-test": "~0.7.0",
    "grunt-mocha-cov": "0.0.7"
  },
  "readme": "# kafkaesque\n\n## A Node.js Kafka client\nkafkaesque is a node.js client for Apache Kafka supporting upwards of v0.8 of the Kafka protocol only. Kafkaesque does not require any connection to zookeeper, rather it uses the kafka metadata protocol request to determine how it should best connect to the cluster. You need only provide Kafkaesque with the details of a single broker in any Kafka cluster and it will figure out the rest.\n\nThe current 0.8 release of Kafka does not appear to support the full protocol set as described here: [https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol](https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol). Specifically the offset/commit/fetch API.\n\nKafkaesque will uses API as opposed to reading meta commit information from zookeeper when it is full supported in Kafka.\n\n## Note\nKafkaesque has an implementation for the offset fetch/commit API, this is not funcitonal in the .8.x Kafka releases. Expected in .9.x release. \n\n## Prerequisites\nYou will need to install Apache Kafka 0.8.x or greater.\n\n## Installation\n\n```\nnpm install kafkaesque\n```\n\n## Quickstart\n\nProduce example:\n\n```\n// create a kafkaesqe client, providing at least one broker\nvar kafkaesque = require('kafkaesque')({\n  brokers: [{host: 'localhost', port: 9092}],\n  clientId: 'MrFlibble',\n  maxBytes: 2000000\n});\n\n// tearup the client\nkafkaesque.tearUp(function() {\n  // send two messages to the testing topic\n  kafkaesque.produce({topic: 'testing', partition: 0}, \n                     ['wotcher mush', 'orwlight geezer'], \n                     function(err, response) {\n    // shutdown connection\n    console.log(response);\n    kafkaesque.tearDown();\n  });\n});\n```\n\nConsume example:\n\n```\n// create a kafkaesqe client, providing at least one broker\nvar kafkaesque = require('kafkaesque')({\n  brokers: [{host: 'localhost', port: 9092}],\n  clientId: 'fish',\n  maxBytes: 2000000\n});\n\n// tearup the client\nkafkaesque.tearUp(function() {\n  // poll the testing topic, kafakesque will determine the lead broker for this\n  // partition / topic pairing and will emit messages as they become available\n  // kafakesque will maintain the read position on the topic based on calls to \n  // commit()\n  kafkaesque.poll({topic: 'testing', partition: 0}, \n                  function(err, kafka) {\n    // handle each message\n    kafka.on('message', function(message, commit) {\n      console.log(JSON.stringify(message));\n      // once a message has been successfull handled, call commit to advance this \n      // consumers position in the topic / parition \n      commit();\n    });\n    // report errors\n    kafka.on('error', function(error) {\n      console.log(JSON.stringify(error));\n    });\n  });\n});\n```\n\n## Samples\nProvided under the samples folder. All of the samples assume a kafka installation on localhost and require that you have created a topic 'testing' on your cluster.\n\n````\ncd samples\nnode metadata.js\n````\n\nWill return metadata information on the topic testing\n\n````\nnode produce.js\n````\n\nWill post two messages to the testing topic\n\n````\nnode fetch.js\n````\n\nWill consume messages from the testing topic. Note that the consume stores its position in the kafka commit log using the commit/offset/fetch API.\n\n\n## Reference\n\n* Configuration\n\t* brokers - array of one or more kafka brokers in the format { host: … , Port: …}\n\t* clientId - reference name for this client\n\t* maxBytes - the maximum number of bytes to return in any one message \n\n* tearUp(cb) - tear up connection to the kafka cluster\n\n* tearDown() - tear down the connection to the kafka cluster\n\n* metadata(params, cb) - return metatdata on a topic\n\t* params.topic - the topic name to return metadata on\n\n* produce(params, messages, cb) - send messages to kafka\n\t* params.topic - the topic name to send to\n\t* params.partition - the partition to send to\n\t* messages - an array of string or object to send as messages\n\n* poll(params, cb) - LONG poll kafka for messages\n\t* params.topic - the topic name, required\n    * params.partition - the partition id, required\n    * offset - the starting offset, if unspecified kafkaesque uses the latest commmited position against this topic / partition pair\n    *  maxWait - the maximum poll wait time, if unspecified defaults to 5 seconds\n    *   minBytes - the minimum bytes that should be available before returning, if unspecified defaults to 50 bytes\n\n## Support\nHope that this code is useful, please feel free to get in touch if you need help or support: @pelger\n\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/pelger/Kafkaesque/issues"
  },
  "_id": "kafkaesque@0.1.1",
  "_from": "kafkaesque@^0.1.1"
}
